\chapter{AWS am Beispiel einer Sharing Energy Plattform}\label{chapter:kapitellabel} %%%%%%%%%%%%%%%%%%%%%%%%%%%%
Nachfolgend möchte ich anhand eines Beispiels aus dem Energiemarkt einige Dienste von AWS näher betrachten und ihre Wirkungsweise im Zusammenhang darstellen.

\section{Das Fallbeispiel}
\label{sec:fallbeispiel}
Bei LichtBlick, Deutschlands größtem unabhängigen Ökostromanbieter, arbeitet aktuell ein Team an einer neuen Plattform-Idee. Grundsätzlich soll es möglich sein, dass sich Personen gegenseitig ihren selbst erzeugten Ökostrom verkaufen, ohne dass ein Stromhändler dazwischen hängt. Ähnliche Produkte gibt es bereits auf dem niederländischen und dem australischen Markt, jedoch noch nicht in Deutschland. Grund hierfür sind diverse Regularien, die es Besitzern von Wind-, Wasserkraft-, Photovoltaik- und Kraft-Wärme-Kopplungs-Anlagen erschweren, ihren Strom direkt zum Verkauf an andere Personen anzubieten. Da die Entwicklung in diesem Bereich noch recht unklar ist, dennoch erste Ideen auf dem deutschen Markt vertestet werden wollen, entscheidet sich das Team für eine agile und schlanke Herangehensweise. Daher fiel die Wahl bei der Frage nach der erforderlichen IT-Infrastruktur auf Amazon Web Services.

\pagebreak
\section{IT-Infrastruktur}
\label{sec:infrastruktur}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1.0\textwidth]{images/peero.png}
  \caption{Infrastruktur für Sharing Energy Plattform }
\end{figure}

\section{Virtuelle Server mit Elastic Compute Cloud}
\label{sec:ec2}
Jede Anwendung im Web benötigt einen Server, auf dem sie ausgeführt werden kann. Der Webservice Elastic Compute Cloud (EC2) bietet virtuelle Server und damit Rechenleistung in der Cloud, welche je nach Bedarf anpassbar sind. \cite{aws:ec2}
Der Entwickler hat die Möglichkeit, Instanzen von Servern innerhalb weniger Minuten aufzusetzen. Dabei kann er wählen, auf welchem Betriebssystem die Instanz basieren (Windows oder Linux) und welche Ressourcenkonfiguration die bereitgestellte Instanz haben soll. \cite{aws:ec2} \\

Eine Instanz wird aus einem Amazon Machine Image (AMI) erzeugt, welches das Betriebssystem und die darauf installierte Software vorgibt. Amazon bietet verschiedene vorkonfigurierte Images basierend auf 64-bit Windows oder verschiedenen 64-bit UNIX-Derivaten. Dem Nutzer stehen jedoch auch Images von Drittanbietern wie IBM oder Oracle zur Verfügung. Darüberhinaus besteht die Möglichkeit, sein eigenes Image zu entwickeln. Einzige Bedingung ist, dass es auf XEN Hypervisor\footnote{https://www.xenproject.org/} ausgeführt werden kann. \cite{baun:cloudcomp}, \cite{vliet:resilience} \\

Die Ressourcenkonfiguration kann sich aufgrund der Leistungsfähigkeit des Prozessors und der Arbeitsspeicher- und Plattengröße unterscheiden. Die Instanzgrößen variieren von einer kleinen Instanz mit 1,7GB Arbeitsspeicher und 1 EC2 Recheneinheit bis hin zu einer High-CPU Extra Large Instanz mit 7GB Arbeitsspeicher und 20 EC2 Recheneinheiten. \cite{vliet:resilience} \\

Darüberhinaus kann der Nutzer entscheiden, innerhalb welcher Availability Zone die Instanz bereitgestellt wird und ob die Instanzen zusätzlich mit persistentem Speicherplatz versehen werden sollen. Dabei hat er die Wahl zwischen zwei Varianten.
\begin{enumerate}
  \item S3-gesichert \\
  Diese Instanztypen können nur neugestartet oder gelöscht werden, da sie einem flüchtigen Speicher entsprechen. Das root device ist Teil der Instanz selbst.
  \item EBS-gesichert \\
  Dieser Typ wird bevorzugt ausgewählt, da Instanzen auch gestoppt und gestartet werden können. Dies wird möglich, da sich die root/boot disk auf einem separaten Elastic Block Store Volume (EBS) befindet, welches unabhängig der Instanz besteht.
\end{enumerate}
\cite{vliet:resilience}, \cite{aws:ec2} \\

Die Instanzen werden in einer virtual private cloud (siehe \ref{sec:vpc}) bereitgestellt. Einem logisch isoliertem Netzwerk, welches verschiedene Netzwerk-Sicherheitsmechanismen mitbringt. Zum Beispiel gehört jede Instanz zu einer oder mehreren Security Groups, um sie gegenüber der Außenwelt abzuschirmen. Angesprochen werden die Instanzen über freigegebene Ports oder IP-Masken. \\
Weiterhin erhalten Instanzen eine öffentliche IP, die sich jedoch mit jeder Bereitstellung der Instanz (z.B. Neustart) ändert. Daher bietet Amazon die Möglichkeit, die öffentliche IPv4-Adresse\footnote{IPv6-Adressen werden derzeit nicht unterstützt} durch eine Elastic IP Adresse auszutauschen. Elastic IP bietet den Vorteil, dass sie konstant bestehen bleibt. Sollte eine Instanz ausfallen, kann die Elastic IP Adresse sehr schnell einer gesunden Instanz zugewiesen werden.
\cite{vliet:resilience}, \cite{aws:eip} \\

In unserem Beispiel verwenden wir aus Gründen der Ausfallsicherheit zwei EC2-Instanzen (Typ: EBS-gesichert) innerhalb eines Clusters, wobei jede zwei identische Services enthält. Den Backend- und den Frontend-Service (siehe \ref{sec:infrastruktur}). Die Clusterung dient der logischen Gruppierung der Instanzen, um geeignete Zugriffsparameter setzen zu können. \\
Jede Instanz liegt in einer anderen Availability Zone in der Region Frankfurt am Main (eu-central-1) und kann auf 4GB Arbeitsspeicher zurückgreifen (Typ: t2.medium). Unterliegend wird ein Linux Image verwendet. \\
Aufgesetzt werden die Instanzen über die AWS API anhand von vordefinierten Konfigurationen, die über TerraForm\footnote{https://www.terraform.io/intro/}-an AWS gesendet werden. Die hierdurch entstehenden Vorteile wurden in Kapitel \ref{sec:vorteile} behandelt. Weitere Möglichkeiten sind
\begin{enumerate}
  \item Amazon Management Konsole
  \item Software Development Kits (SDKs)
  \item Command Line Interface
\end{enumerate} \cite{wittig:awsinaction}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.7\textwidth]{images/awsapi.png}
  \caption{Interaktionsmöglichkeiten mit der AWS API \cite{wittig:awsinaction}}
\end{figure}

\section{EC2-Container Service}
\label{sec:ecs}
Da unsere Services innerhalb von Docker-Containern laufen, nutzen wir den von Amazon angebotenen EC2-Container Service (ECS). Dieser Dienst wurde speziell für die Unterstützung von Docker-Containern auf EC2-Instanzen entwickelt und erlaubt neben dem Betrieb auch die Verwaltung der Anwendungen auf einem verwalteten EC2-Instanz-Cluster. Der Betrieb einer eigenen Cluster-Managementinfrastruktur entfällt. Funktionen wie Sicherheitsgruppen, Elastic Load Balancing, EBS-Volumes und IAM-Rollen stehen daneben ebenfalls zur Verfügung \cite{aws:ecs}.

\section{Auto-Scaling}
\label{sec:auto-scaling}
Beide Instanzen laufen innerhalb einer Security Group, welche wiederum in einer Auto-Scaling Group liegt. Letztere ermöglicht eine elastische Instanzgruppe, deren bereitgestellte Ressourcen sich je nach Bedarf anpassen. Das Auto-Scaling basiert dabei auf CloudWatch-Metriken wie z.B. CPU-Auslastung. Beispielsweise könnte eine Metrik besagen, dass zwei neue Instanzen gestartet werden sollen, wenn die CPU Auslastung der bestehenden Instanz(en) für 5 Minuten bei 60\% oder höher liegt. CloudWatch ist ein Service, der verschiedene Informationen der verwendeten IT-Ressourcen überwacht und misst. Von der Betrachtung einzelner Instanzen bis hin zur Überwachung aller Instanzen einer Region ist nahezu alles möglich. Es ist jedoch auch denkbar, dass die Ressourcenanpassung der Gruppe auf Amazons verteilten Queue-System SQS basiert. Dann würden sich die Ressourcen nach der Anzahl der Items in der Queue richten. \cite{vliet:resilience}, \cite{vliet:programmingec2} \\

In unserem Projekt haben wir noch keine konkreten Metriken definiert, die für das AutoScaling herangezogen werden sollen. Allerdings würden wir uns vermutlich im ersten Schritt auf die CPU-Auslastung stützen.

\section{Load Balancing}
\label{sec:elb}
Der gesamten Gruppe vorgesetzt ist ein Application Load Balancer (ALB), der die Instanzen vom öffentlichen Internet loslöst. Ein ALB ist eine von zwei Lastenverteilungsoptionen\footnote{neben Classic Load Balancer; \\vgl. Funktionen https://aws.amazon.com/de/elasticloadbalancing/classicloadbalancer/faqs/} des Services Elastic Load Balancing.
Der Elastic Load Balancer (ELB) sitzt vor einer Gruppe von EC2-Instanzen und kann jede Art von TCP Traffic verteilen. Bei der Kommunikation mit den Instanzen nutzt der ELB HTTP und wandelt ggf. vorher eingegangenes HTTPS in HTTP um. Dieses Vorgehen reduziert die Belastung der Instanzen und erhöht damit die Fehlertoleranz. Bei der Verteilung des Traffics achtet der ELB auf eine gleichmäßige Verteilung auf alle Availability Zonen und in jeder AZ auf die gleichmäßige Aufteilung auf die vorhandenen Instanzen. Dies erhöht die Sicherheit und reduziert die Komplexität der Infrastruktur. Dem ELB kann ein Hostname zugeordnet werden, worüber dieser direkt angesprochen werden kann. \\
Wird der ELB zusammen mit einer Auto-Scaling Group betrieben, kann dieser je nach Bedarf automatisch Instanzen registrieren und bei Nicht-Gebrauch auch wieder abmelden. Eine manuelle Zuordnung der IPs zu den jeweiligen Instanzen ist damit nicht mehr nötig. Bei der Abmeldung einer bestehenden Instanz und nachfolgender Neu-Registrierung einer neuen Instanz kann es unter Umständen kurzzeitig dazu kommen, dass der Dienst nicht zur Verfügung steht. Dieses Problem ist bekannt und entsteht dadurch, dass die alte Instanz erst beendet wird, ehe die neue Instanz hochgefahren werden kann.
\cite{vliet:resilience}, \cite{aws:elb} \\

\subsection{Application Load Balancer}
\label{sec:alb}
Bei dem zuvor erwähnten ALB, welchen wir im Einsatz haben, verteilt sich der eingehende Traffic auf erweiterte Anwendungsinformationen, die die Inhalte der Anfrage enthalten. Damit eignet sich dieser Typ besonders für Anwendungen mit der Notwendigkeit erweiterter Routing-Funktionen, Microservices und Container-basierten Architekturen. Ein ALB ermöglicht die Lastenverteilung auf mehrere Ports einer EC2-Instanz, aber auch die Umleitung auf mehrere Services. Letzteres wird durch Target Groups (siehe \ref{sec:target-group}) und inhaltsbasiertes Routing ermöglicht, welches Anfragen basierend auf ihrem Inhalt an den entsprechenden Service weiterleitet.\footnote{weitere Funktionen des ALBs können \cite{aws:alb} entnommen werden} \cite{aws:elb}, \cite{aws:alb}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.9\textwidth]{images/routing.png}
  \caption{Screenshot aus AWS-Entwicklerkonsole mit Listener-Regeln des ALB für inhaltsbasiertes Routing}
\end{figure}

\subsection{Target-Group}
\label{sec:target-group}
Eine Target Group ist eine Gruppierung von Instanzen oder Microservices innerhalb der Instanzen, damit Anfragen durch den ALB (siehe \ref{sec:alb}) gezielt an den zuständigen Dienst geroutet werden können. Hierfür wird eine Target Group als eine Regel für einen Listener des Load Balancers definiert. Jede Target Group nutzt die Standard Health Check- Einstellungen eines Load Balancers. Auf Basis dessen kann der Load Balancer ausschließlich gesunde Targets ansprechen. \cite{aws:target} \\

In unserem Fallbeispiel gibt es zwei Target Groups. In beiden befinden sich beide verfügbaren Instanzen als Targets. Wie bereits in Kapitel \ref{sec:ec2} beschrieben, befinden sich in jeder Instanz jeweils zwei Services, weshalb die eigentliche Logik der Target Groups bei uns (noch) nicht korrekt greift. Richtiger wäre eine Target Group für alle Backend-Services und eine Target Group für alle Frontend-Services. Je nach Auslastung würde dann der eine über den anderen Service innerhalb der Target Group bevorzugt angesprochen. Unser Aufbau ist derzeit noch der Tatsache geschuldet, dass wir lediglich zwei Instanzen innerhalb unseres Clusters haben und der Scheduler die Container für einen Service bestmöglich gleichmäßig darauf verteilt.


\section{Virtual Private Cloud}
\label{sec:vpc}
Der im vorherigen Kapitel erwähnte ALB ist der einzige Kontakt zur Außenwelt. Dies dient zum einen der Sicherheit und zum anderen dem Pragmatismus, da nicht für jeden einzelnen virtuellen Server ein DNS Name vergeben und verwaltet werden muss. Der ALB bekommt einen eindeutigen Hostnamen, über den der ALB und damit alle dahinterliegenden Services innerhalb der definierten Security Groups erreichbar sind. Die Security Groups bieten jedoch nicht ausreichend Kontrollmöglichkeiten für das sichere Handling der Anfragen. Zum Beispiel ist es in normalen Security Groups nicht möglich, eingehende Anfragen zu beschränken. Um eingehenden und ausgehenden Datenverkehr kontrollieren zu können, bietet Amazon die Virtual Private Cloud (VPC) an. \\
Der Einsatz der VPC ermöglicht es uns, die beiden EC2-Instanzen in einem privaten Sub-Netzwerk unterzubringen. Der ALB befindet sich im öffentlichen Netzwerk, welches von außen sichtbar ist. Anfragen gelangen per HTTPS über den Hostnamen zum ALB, wo sie umgewandelt und per HTTP an die jeweiligen Services in den EC2-Instanzen weitergeleitet werden.
\cite{vliet:resilience}, \cite{wittig:awsinaction}, \cite{aws:vpc}

\section{Simple Storage Service}
\label{sec:s3}
Zur dauerhaften Speicherung erhobener Daten der Nutzer verwenden wir den neben EC2 zweiten Basisdienst für Webanwendungen: Amazons Simple Storage Service (S3). Ein virtueller Objekt-Speicher zur Speicherung einer unbegrenzten Datenmenge. Amazon proklamiert eine 99,999999999\% Haltbarkeit und 99,99\% Verfügbarkeit der Daten. Es soll nahezu unmöglich sein, dass Dateien kaputt oder verloren gehen. Amazons Chief Evangelist Jeff Barr beschreibt es so \\
\begin{quote}
"`If you store 10.000 objects with us, on average we may lose one of them every 10 million years or so."'
\end{quote} \cite{vliet:programmingec2}

Sichergestellt wird dies über ein Service Level Agreement. \cite{vliet:programmingec2}

Zu speichernde Objekte werden in buckets vorgehalten. Diese können in jeder Region erstellt werden und eine unbegrenzte Anzahl Objekte mit Größen zwischen 1Byte und 5TB enthalten. Zur Speicherung statischer Informationen von Webseiten oder mobilen Anwendungen ist S3 weniger geeignet. Hierfür kann der Nutzer auf CloudFront ausweichen. Einem Content Distribution Network, das dem Verteilen statischer, dynamischer und gestreamter Inhalte über die gesamte Welt dient.
\cite{vliet:resilience}, \cite{aws:s3}

\section{Identity Access Management}
\label{sec:iam}
Zur Einschränkung der Zugriffsmöglichkeiten für Nutzer auf die IT-Ressourcen in AWS und damit zur Erhöhung der Sicherheit, bietet AWS den Identity and Access Management Service (IAM). Dieser Service prüft jede Anfrage auf deren Zulässigkeit. Zugriffe können über policies Benutzer- oder Gruppenscharf organisiert werden. Die Authentifizierung der Nutzer gegenüber der Services erfolgt über die Anmeldedaten der Benutzer. IAM bietet neben der Zugriffsverwaltung auch
\begin{itemize}
  \item Multi Factor Authentification (MFA) als zweiten Authentifizierungsschritt für bestimmte Operationen
  \item das Hinzufügen von Rollen zu EC2 Instanzen, wodurch die Festlegungen für die Rolle die Zugriffsmöglichkeiten auf die Instanz bestimmen
\end{itemize}
\cite{vliet:resilience}, \cite{wittig:awsinaction}

% keep an blank line above
